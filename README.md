# Turkish-NLP-Preprocessing-module
Preprocessing tool for Turkish NLP that contains tokenizer, normalizer, stop-word eliminator and stemmer.
Developed by Melikşah Türker and Büşra Oğuzoğlu for CMPE561 class project.

Sentence Splitter and Tokenizer modules have 2 versions, rule-based and machine learning based.

Stop-Word eliminator has 2 versions, static and dynamic. Static one requires pre-defined stopwords, while dynamic one detects the stop-words using second derivative of word distribution.

Data folder contains lots of lexicons for multi-word-expressions, normalization, prefixes, abbreviations(non-breaking prefixes), stop-words, etc.
